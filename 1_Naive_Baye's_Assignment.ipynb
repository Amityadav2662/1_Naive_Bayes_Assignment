{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecbbe3-85ef-47fb-9235-f1a226577eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Bayes' theorem?\n",
    "Ans. Bayes' theorem is a fundamental concept which is use for probability theory and statistics. It provides\n",
    "a way to update probability based on new evidence and information. The Bayes' theorem is particularly used for \n",
    "bayesian theorem and machine learning.\n",
    "Formula:\n",
    "    Pr(A/B) = Pr(A) * Pr(B/A) / Pr(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f21ae-ae6e-4fca-a458-6c24bb9fca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the formula for Bayes' theorem?\n",
    "Ans. \n",
    "The Formula for Bayes' theorem is:\n",
    "    Pr(A/B) = Pr(A) * Pr(B/A) / Pr(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc4799-3fb8-4af6-a800-578cc937810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How is Bayes' theorem used in practice?\n",
    "Bayes' theorem is used in a wide range of practical applications, from medical diagnosis to spam filtering. Here\n",
    "are a few examples:\n",
    "Medical diagnosis: Bayes' theorem can be used to calculate the probability of a patient having a particular disease,\n",
    "based on their symptoms and other diagnostic tests. For example, if a patient presents with a certain set of symptoms,\n",
    "a doctor can use Bayes' theorem to calculate the probability of a specific disease, and then order additional tests to\n",
    "confirm the diagnosis.\n",
    "\n",
    "Spam filtering: Bayes' theorem can be used to classify emails as spam or non-spam. The algorithm looks at the words in\n",
    "the email and calculates the probability that the email is spam, based on the frequency of words that are commonly found\n",
    "in spam emails.\n",
    "\n",
    "Risk assessment: Bayes' theorem can be used to assess the risk of a particular event occurring, such as a natural disaster\n",
    "or a terrorist attack. The probability of the event can be estimated based on historical data and other relevant information,\n",
    "and then used to inform decision-making and risk management strategies.\n",
    "\n",
    "Machine learning: Bayes' theorem is used in various machine learning algorithms, such as Naive Bayes classifiers, which can be\n",
    "trained to predict the probability of a certain outcome based on a set of input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e72b9-f073-4db1-8e4d-32311d9e4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Ans. \n",
    "Bayes' theorem:\n",
    "Bayes theorem is a mathematical formula, which is used to determine the conditional probability of a given event.\n",
    "It provides a way to update probability based on new evidence and information.\n",
    "\n",
    "Conditional Probability :\n",
    "The probability of occurrence of any event A when another event B in relation to A has already occurred is known as\n",
    "conditional probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe391c-b282-439c-9104-8a4c1a589af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "Ans. \n",
    "There are three type of Naive Bayes classifier:\n",
    "Gaussian Naive Bayes:\n",
    "Assumption: Assumes that the features follow a normal (Gaussian) distribution.\n",
    "Use Case: Suitable for continuous data where the feature values are real numbers. Commonly used in classification problems\n",
    "with continuous features.\n",
    "\n",
    "Multinomial Naive Bayes:\n",
    "Assumption: Assumes that the features represent the frequencies with which certain events have been generated by a multinomial\n",
    "distribution.\n",
    "Use Case: Typically used for discrete data, especially when dealing with text data and word counts. Commonly applied in natural\n",
    "language processing tasks such as text classification and spam filtering.\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "Assumption: Assumes that features are binary variables (i.e., they take values of 0 or 1), representing the presence or absence\n",
    "of a particular feature.\n",
    "Use Case: Suitable for binary and boolean features. Often used in document classification tasks where the presence or absence of\n",
    "specific words is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1742343-f92a-4c43-8388-3ac9f902e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Assignment:\n",
    "# You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "# Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "# each feature value for each class:\n",
    "# Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "# A 3 3 4 4 3 3 3\n",
    "# B 2 2 1 2 2 2 3\n",
    "# Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "# to belong to?\n",
    "\n",
    "Ans.\n",
    "Step 1: Assume the prior probabilities\n",
    " P(A)=P(B)=0.5\n",
    "    \n",
    "Step 2: Calculate the likelihood\n",
    "For class A:\n",
    "P(X1=3∣A) = 4/10 = 0.4\n",
    "P(X2=4∣A) = 3/10 = 0.3\n",
    "\n",
    "For class B:\n",
    "P(X1=3∣B) = 1/9 = 0.111\n",
    "P(X2=4∣B) = 3/9 = 0.333\n",
    "\n",
    "Step 3: Calculate Joint Probability:\n",
    "\n",
    "For class A:\n",
    "P(A∣X1=3,X2=4) = P(X1=3∣A)×P(X2=4∣A)×P(A)\n",
    "              = 0.4 × 0.3 × 0.5 = 0.06\n",
    "\n",
    "For class B:\n",
    "P(B∣X1=3,X2=4) = P(X1=3∣B)×P(X2=4∣B)×P(B)\n",
    "               = 0.111 × 0.333 × 0.5 = 0.0185\n",
    "\n",
    "Step 4: Normalize the Probabilities:\n",
    "Normalize so that  P(A∣X1=3,X2=4) + P(B∣X1=3,X2=4) = 1\n",
    "\n",
    "P(A∣X1=3,X2=4)= 0.06 + 0.0185 / 0.06 = 0.764\n",
    "P(B∣X1=3,X2=4)= 0.06 + 0.0185 / 0.0185 = 0.236\n",
    "\n",
    "Step 5 : Make a Prediction:\n",
    "The class with the higher probability is A. Therefore, Naive Bayes would predict that the new instance with features \n",
    "X1=3 and X2=4 belongs to class A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
